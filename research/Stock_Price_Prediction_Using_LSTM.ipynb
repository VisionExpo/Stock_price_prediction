{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandas_datareader as pdr\n",
    "import numpy as np\n",
    "from numpy import array\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "import math\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "tiingo_api_key = os.getenv(\"TIINGO_API_KEY\")\n",
    "\n",
    "df = pdr.get_data_tiingo('AAPL', api_key=tiingo_api_key)\n",
    "\n",
    "print(df)\n",
    "\n",
    "df.to_csv('AAPL.csv')\n",
    "!pip install python-dotenv\n",
    "\n",
    "df = pd.read_csv('AAPL.csv')\n",
    "df.head()\n",
    "df.tail()\n",
    "df1 = df.reset_index()['close']\n",
    "df1.shape\n",
    "df1\n",
    "\n",
    "plt.plot(df1)\n",
    "### lstm is sensitive to the scale of the data. apply minmax scaler\n",
    "\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "\n",
    "df1 = scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
    "df1\n",
    "### spliting dataset into train and test split\n",
    "\n",
    "training_size = int(len(df1)*0.7)\n",
    "\n",
    "test_size = len(df1)-training_size\n",
    "\n",
    "train_data,test_data = df1[0:training_size,:],df1[training_size:len(df1),:1]\n",
    "training_size,test_size\n",
    "\n",
    "import numpy\n",
    "\n",
    "def create_dataset(dataset,time_step=1):\n",
    "  dataX, dataY = [], []\n",
    "  for i in range(len(dataset)-time_step-1):\n",
    "    a = dataset[i:(i+time_step),0]\n",
    "    dataX.append(a)\n",
    "    dataY.append(dataset[i + time_step, 0])\n",
    "  return numpy.array(dataX), numpy.array(dataY)\n",
    "\n",
    "time_step = 100\n",
    "\n",
    "x_train , y_train = create_dataset(train_data, time_step)\n",
    "\n",
    "x_test , y_test = create_dataset(test_data, time_step)\n",
    "print(x_train)\n",
    "x_train.shape,x_test.shape\n",
    "### reshape df to 3D i.e (samples,time step,features)\n",
    "\n",
    "x_train = x_train.reshape(x_train.shape[0],x_train.shape[1],1)\n",
    "\n",
    "x_test = x_test.reshape(x_test.shape[0],x_test.shape[1],1)\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(100,return_sequences=True,input_shape=(100,1)))\n",
    "\n",
    "model.add(LSTM(100,return_sequences=True))\n",
    "\n",
    "model.add(LSTM(100))\n",
    "\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(loss = 'mean_squared_error', optimizer = 'adam')\n",
    "model.summary()\n",
    "model.fit(x_train, y_train, validation_data=(x_test,y_test),epochs=100,batch_size=64,verbose=1)\n",
    "###prediction\n",
    "\n",
    "train_predict = model.predict(x_train)\n",
    "\n",
    "test_predict = model.predict(x_test)\n",
    "### transfrom to original from\n",
    "\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "### train data RMSE\n",
    "\n",
    "math.sqrt(mean_squared_error(y_train,train_predict))\n",
    "### test data RMSE\n",
    "\n",
    "math.sqrt(mean_squared_error(y_test,test_predict))\n",
    "### plot gragh\n",
    "\n",
    "# shift train prediction for ploting\n",
    "\n",
    "look_back = 100\n",
    "\n",
    "trainPredictPlot = numpy.empty_like(df1)\n",
    "\n",
    "trainPredictPlot[:,:]= np.nan\n",
    "\n",
    "trainPredictPlot[look_back:len(train_predict)+look_back,:] = train_predict\n",
    "\n",
    "#shift test predictions for plotting\n",
    "\n",
    "testPredictPlot = numpy.empty_like(df1)\n",
    "\n",
    "testPredictPlot[:,:] = np.nan\n",
    "\n",
    "testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1,:] = test_predict\n",
    "\n",
    "#plot baselines and predictions\n",
    "\n",
    "plt.plot(scaler.inverse_transform(df1))\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()\n",
    "len(test_data)\n",
    "x_input = test_data[278:].reshape(1,-1)\n",
    "\n",
    "x_input.shape\n",
    "temp_input = list(x_input)\n",
    "\n",
    "temp_input = temp_input[0].tolist()\n",
    "temp_input\n",
    "### predicting next 30 days price\n",
    "\n",
    "lst_output=[]\n",
    "\n",
    "n_steps=100\n",
    "\n",
    "i=0\n",
    "\n",
    "while(i<30):\n",
    "\n",
    "  if (len(temp_input)>100):\n",
    "\n",
    "    x_input = np.array(temp_input[1:])\n",
    "\n",
    "    print(\"{} day input {}\".format(i,x_input))\n",
    "\n",
    "    x_input = x_input.reshape(1,-1)\n",
    "\n",
    "    x_input = x_input.reshape((1,n_steps,1))\n",
    "\n",
    "    #print(x_input)\n",
    "\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "    print(\"{} day output {}\".format(i,yhat))\n",
    "\n",
    "    temp_input.extend(yhat[0].tolist())\n",
    "\n",
    "    temp_input = temp_input[1:]\n",
    "\n",
    "    # print temp_input\n",
    "\n",
    "    lst_output.extend(yhat.tolist())\n",
    "\n",
    "    i=i+1\n",
    "\n",
    "  else:\n",
    "\n",
    "    x_input = x_input.reshape((1, n_steps,1))\n",
    "\n",
    "    yhat = model.predict(x_input, verbose=0)\n",
    "\n",
    "    print(yhat[0])\n",
    "\n",
    "    temp_input.extend(yhat[0].tolist())\n",
    "\n",
    "    print(len(temp_input))\n",
    "\n",
    "    lst_output.extend(yhat.tolist())\n",
    "\n",
    "    i=i+1\n",
    "\n",
    "print(lst_output)\n",
    "day_new = np.arange(1,101)\n",
    "day_pred = np.arange(101,131)\n",
    "len(df1)\n",
    "df3 = df1.tolist()\n",
    "df3.extend(lst_output)\n",
    "plt.plot(day_new,scaler.inverse_transform(df1[1159:]))\n",
    "plt.plot(day_pred,scaler.inverse_transform(lst_output))\n",
    "df3=df1.tolist()\n",
    "df3.extend(lst_output)\n",
    "plt.plot(df3[:])\n",
    "model.save(\"stock\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
   "name": "ipython",
   "version": 3
   },
   "file_extension": ".ipynb",
   "mimetype": "application/x-ipynb+json",
   "name": "ipython",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "7.16.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
</create_file>
