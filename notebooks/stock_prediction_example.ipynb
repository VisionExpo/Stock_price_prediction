{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Price Prediction Example\n",
    "\n",
    "This notebook demonstrates how to use the Stock Price Prediction model to predict future stock prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import pandas_datareader as pdr\n",
    "\n",
    "# Add the project root to the path\n",
    "sys.path.append('..')\n",
    "\n",
    "# Import project modules\n",
    "from src.model import create_model, train_model\n",
    "from src.predict import predict_future\n",
    "from src.utils import create_dataset, preprocess_data, calculate_metrics, plot_predictions\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set plot style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fetch Stock Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set stock symbol and date range\n",
    "symbol = 'AAPL'\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "# Get API key from environment variables\n",
    "api_key = os.getenv(\"TIINGO_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"TIINGO_API_KEY not found in environment variables. Please add it to .env file.\")\n",
    "\n",
    "# Fetch data from Tiingo\n",
    "df = pdr.get_data_tiingo(symbol, api_key=api_key, start=start_date, end=end_date)\n",
    "\n",
    "# Reset index if multi-level\n",
    "if isinstance(df.index, pd.MultiIndex):\n",
    "    df = df.reset_index()\n",
    "\n",
    "# Ensure column names are lowercase\n",
    "df.columns = [col.lower() for col in df.columns]\n",
    "\n",
    "# Display the first few rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualize the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot the closing price\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(df['date'], df['close'], label='Close Price')\n",
    "plt.title(f'{symbol} Stock Price (2020-2023)')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Preprocess the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set parameters\n",
    "look_back = 60  # Number of previous time steps to use as input\n",
    "train_size = 0.8  # Proportion of data to use for training\n",
    "\n",
    "# Preprocess data\n",
    "X_train, Y_train, X_test, Y_test, scaler = preprocess_data(df['close'], look_back, train_size)\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Create and Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create model\n",
    "input_shape = (look_back, 1)\n",
    "model = create_model(input_shape)\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set training parameters\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, Y_train,\n",
    "    validation_data=(X_test, Y_test),\n",
    "    epochs=epochs,\n",
    "    batch_size=batch_size,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Make predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Inverse transform predictions\n",
    "train_predict_original = scaler.inverse_transform(train_predict)\n",
    "Y_train_original = scaler.inverse_transform(Y_train.reshape(-1, 1))\n",
    "test_predict_original = scaler.inverse_transform(test_predict)\n",
    "Y_test_original = scaler.inverse_transform(Y_test.reshape(-1, 1))\n",
    "\n",
    "# Calculate metrics\n",
    "train_metrics = calculate_metrics(Y_train_original, train_predict_original)\n",
    "test_metrics = calculate_metrics(Y_test_original, test_predict_original)\n",
    "\n",
    "print(\"Training Metrics:\")\n",
    "for metric, value in train_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")\n",
    "\n",
    "print(\"\\nTesting Metrics:\")\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Create a dataframe with actual and predicted values\n",
    "results_df = pd.DataFrame({\n",
    "    'Actual': Y_test_original.flatten(),\n",
    "    'Predicted': test_predict_original.flatten()\n",
    "})\n",
    "\n",
    "# Plot actual vs predicted\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(results_df.index, results_df['Actual'], label='Actual')\n",
    "plt.plot(results_df.index, results_df['Predicted'], label='Predicted', alpha=0.7)\n",
    "plt.title(f'{symbol} Stock Price Prediction')\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Predict Future Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Set the number of days to predict\n",
    "future_days = 30\n",
    "\n",
    "# Get the last sequence from the test data\n",
    "last_sequence = X_test[-1:]\n",
    "\n",
    "# Predict future values\n",
    "future_predictions = []\n",
    "current_sequence = last_sequence[0]\n",
    "\n",
    "for _ in range(future_days):\n",
    "    # Reshape for prediction\n",
    "    current_sequence_reshaped = current_sequence.reshape(1, look_back, 1)\n",
    "    \n",
    "    # Predict next value\n",
    "    next_pred = model.predict(current_sequence_reshaped)[0, 0]\n",
    "    \n",
    "    # Add to predictions\n",
    "    future_predictions.append(next_pred)\n",
    "    \n",
    "    # Update sequence\n",
    "    current_sequence = np.append(current_sequence[1:], next_pred)\n",
    "\n",
    "# Convert to numpy array\n",
    "future_predictions = np.array(future_predictions).reshape(-1, 1)\n",
    "\n",
    "# Inverse transform\n",
    "future_predictions_original = scaler.inverse_transform(future_predictions)\n",
    "\n",
    "# Create date range for future predictions\n",
    "last_date = pd.to_datetime(df['date'].iloc[-1])\n",
    "future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=future_days)\n",
    "\n",
    "# Create dataframe for future predictions\n",
    "future_df = pd.DataFrame({\n",
    "    'Date': future_dates,\n",
    "    'Predicted': future_predictions_original.flatten()\n",
    "})\n",
    "\n",
    "# Display future predictions\n",
    "future_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Plot historical data and future predictions\n",
    "plt.figure(figsize=(16, 8))\n",
    "\n",
    "# Plot historical data\n",
    "plt.plot(df['date'], df['close'], label='Historical Data', color='blue')\n",
    "\n",
    "# Plot future predictions\n",
    "plt.plot(future_df['Date'], future_df['Predicted'], label='Future Predictions', color='red', linestyle='--')\n",
    "\n",
    "# Add vertical line to separate historical data and predictions\n",
    "plt.axvline(x=last_date, color='green', linestyle='-', alpha=0.7, label='Prediction Start')\n",
    "\n",
    "plt.title(f'{symbol} Stock Price Prediction for Next {future_days} Days')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Save the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Save the model\n",
    "model.save('../models/stock_prediction_model.h5')\n",
    "print(\"Model saved to '../models/stock_prediction_model.h5'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "In this notebook, we've demonstrated how to:\n",
    "1. Fetch historical stock data using the Tiingo API\n",
    "2. Preprocess the data for LSTM model training\n",
    "3. Create and train an LSTM model\n",
    "4. Evaluate the model's performance\n",
    "5. Make predictions on test data\n",
    "6. Predict future stock prices\n",
    "7. Visualize the results\n",
    "\n",
    "The model's performance can be further improved by:\n",
    "- Using more historical data\n",
    "- Adding more features (e.g., technical indicators)\n",
    "- Tuning hyperparameters\n",
    "- Trying different model architectures\n",
    "- Implementing ensemble methods"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
